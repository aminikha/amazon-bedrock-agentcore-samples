{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06fd6a95-a0f2-495f-86bc-89d56ac23557",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab781a4-448d-4724-90b6-7a9c33aa2ea5",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d32a88b-bc3f-44d9-b696-ee70bb1580d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install -r requirements.txt --quiet --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944d56fc-6bab-4b65-9ecd-c08a70247ebd",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91a6e873-b421-4fc2-8925-10a3ef2512ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import uuid\n",
    "import sqlite3\n",
    "import boto3\n",
    "import functools\n",
    "import requests\n",
    "import pytz\n",
    "import time\n",
    "import warnings\n",
    "from ast import literal_eval\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from botocore.config import Config\n",
    "from typing import Annotated, Literal, Optional, Union\n",
    "from typing_extensions import TypedDict\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, datetime\n",
    "\n",
    "\n",
    "from langchain.globals import set_debug\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage, RemoveMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda, Runnable\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent, ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "set_debug(False)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7fbd5-d435-43d0-bd73-a28abf8687d0",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92fc1424-cf4c-408b-b796-52f64c3abc46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class State(TypedDict):\n",
    "#     # Messages have the type \"list\". The `add_messages` function\n",
    "#     # in the annotation defines how this state key should be updated\n",
    "#     # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "#     messages: Annotated[list, add_messages]\n",
    "#     # data: df\n",
    "\n",
    "thread = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"2\"\n",
    "    },\n",
    "    \"recursion_limit\": 50\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa83278-7887-42e6-8450-ced7460ead08",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tools\n",
    "\n",
    "#### Populate the database\n",
    "\n",
    "Run the next script to fetch a `sqlite` DB we've prepared for this tutorial and update it to look like it's current. The details are unimportant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a82923a9-a5e9-4c5b-8f13-d4d8e9f20f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_url = \"https://storage.googleapis.com/benchmarks-artifacts/travel-db/travel2.sqlite\"\n",
    "local_file = \"travel2.sqlite\"\n",
    "# The backup lets us restart for each tutorial section\n",
    "backup_file = \"travel2.backup.sqlite\"\n",
    "overwrite = False\n",
    "if overwrite or not os.path.exists(local_file):\n",
    "    response = requests.get(db_url)\n",
    "    response.raise_for_status()  # Ensure the request was successful\n",
    "    with open(local_file, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    # Backup - we will use this to \"reset\" our DB in each section\n",
    "    shutil.copy(local_file, backup_file)\n",
    "\n",
    "\n",
    "# Convert the flights to present time for our tutorial\n",
    "def update_dates(file):\n",
    "    shutil.copy(backup_file, file)\n",
    "    conn = sqlite3.connect(file)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    tables = pd.read_sql(\n",
    "        \"SELECT name FROM sqlite_master WHERE type='table';\", conn\n",
    "    ).name.tolist()\n",
    "    tdf = {}\n",
    "    for t in tables:\n",
    "        tdf[t] = pd.read_sql(f\"SELECT * from {t}\", conn)\n",
    "\n",
    "    example_time = pd.to_datetime(\n",
    "        tdf[\"flights\"][\"actual_departure\"].replace(\"\\\\N\", pd.NaT)\n",
    "    ).max()\n",
    "    current_time = pd.to_datetime(\"now\").tz_localize(example_time.tz)\n",
    "    time_diff = current_time - example_time\n",
    "\n",
    "    tdf[\"bookings\"][\"book_date\"] = (\n",
    "        pd.to_datetime(tdf[\"bookings\"][\"book_date\"].replace(\"\\\\N\", pd.NaT), utc=True)\n",
    "        + time_diff\n",
    "    )\n",
    "\n",
    "    datetime_columns = [\n",
    "        \"scheduled_departure\",\n",
    "        \"scheduled_arrival\",\n",
    "        \"actual_departure\",\n",
    "        \"actual_arrival\",\n",
    "    ]\n",
    "    for column in datetime_columns:\n",
    "        tdf[\"flights\"][column] = (\n",
    "            pd.to_datetime(tdf[\"flights\"][column].replace(\"\\\\N\", pd.NaT)) + time_diff\n",
    "        )\n",
    "\n",
    "    for table_name, df in tdf.items():\n",
    "        df.to_sql(table_name, conn, if_exists=\"replace\", index=False)\n",
    "    del df\n",
    "    del tdf\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    return file\n",
    "\n",
    "\n",
    "db = update_dates(local_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4016fdd9-555c-43b0-849c-39260ae74407",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Flights\n",
    "\n",
    "Define the (`fetch_user_flight_information`) tool to let the agent see the current user's flight information.  Then define tools to search for flights and manage the passenger's bookings stored in the SQL database.\n",
    "\n",
    "We the can [access the RunnableConfig](https://python.langchain.com/docs/how_to/tool_configure/#inferring-by-parameter-type) for a given run to check the `passenger_id` of the user accessing this application. The LLM never has to provide these explicitly, they are provided for a given invocation of the graph so that each user cannot access other passengers' booking information.\n",
    "\n",
    "<div class=\"admonition warning\">\n",
    "    <p class=\"admonition-title\">Compatibility</p>\n",
    "    <p>\n",
    "        This tutorial expects `langchain-core>=0.2.16` to use the injected RunnableConfig. Prior to that, you'd use `ensure_config` to collect the config from context.\n",
    "    </p>\n",
    "</div> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef806cc6-1746-464a-9cd2-d0639c228cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def fetch_user_flight_information(config: RunnableConfig) -> list[dict]:\n",
    "    \"\"\"Fetch all tickets for the user along with corresponding flight information and seat assignments.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries where each dictionary contains the ticket details,\n",
    "        associated flight details, and the seat assignments for each ticket belonging to the user.\n",
    "    \"\"\"\n",
    "    configuration = config.get(\"configurable\", {})\n",
    "    passenger_id = configuration.get(\"passenger_id\", None)\n",
    "    if not passenger_id:\n",
    "        raise ValueError(\"No passenger ID configured.\")\n",
    "\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        t.ticket_no, t.book_ref,\n",
    "        f.flight_id, f.flight_no, f.departure_airport, f.arrival_airport, f.scheduled_departure, f.scheduled_arrival,\n",
    "        bp.seat_no, tf.fare_conditions\n",
    "    FROM \n",
    "        tickets t\n",
    "        JOIN ticket_flights tf ON t.ticket_no = tf.ticket_no\n",
    "        JOIN flights f ON tf.flight_id = f.flight_id\n",
    "        JOIN boarding_passes bp ON bp.ticket_no = t.ticket_no AND bp.flight_id = f.flight_id\n",
    "    WHERE \n",
    "        t.passenger_id = ?\n",
    "    \"\"\"\n",
    "    cursor.execute(query, (passenger_id,))\n",
    "    rows = cursor.fetchall()\n",
    "    column_names = [column[0] for column in cursor.description]\n",
    "    results = [dict(zip(column_names, row)) for row in rows]\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return results \n",
    "\n",
    "\n",
    "@tool\n",
    "def search_flights(\n",
    "    departure_airport: Optional[str] = None,\n",
    "    arrival_airport: Optional[str] = None,\n",
    "    start_time: Optional[date | datetime] = None,\n",
    "    end_time: Optional[date | datetime] = None,\n",
    "    limit: int = 20,\n",
    ") -> list[dict]:\n",
    "    \"\"\"Search for flights based on departure airport, arrival airport, and departure time range.\"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = \"SELECT * FROM flights WHERE 1 = 1\"\n",
    "    params = []\n",
    "\n",
    "    if departure_airport:\n",
    "        query += \" AND departure_airport = ?\"\n",
    "        params.append(departure_airport)\n",
    "\n",
    "    if arrival_airport:\n",
    "        query += \" AND arrival_airport = ?\"\n",
    "        params.append(arrival_airport)\n",
    "\n",
    "    if start_time:\n",
    "        query += \" AND scheduled_departure >= ?\"\n",
    "        params.append(start_time)\n",
    "\n",
    "    if end_time:\n",
    "        query += \" AND scheduled_departure <= ?\"\n",
    "        params.append(end_time)\n",
    "    query += \" LIMIT ?\"\n",
    "    params.append(limit)\n",
    "    cursor.execute(query, params)\n",
    "    rows = cursor.fetchall()\n",
    "    column_names = [column[0] for column in cursor.description]\n",
    "    results = [dict(zip(column_names, row)) for row in rows]\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return results \n",
    "\n",
    "\n",
    "@tool\n",
    "def update_ticket_to_new_flight(\n",
    "    ticket_no: str, new_flight_id: int, *, config: RunnableConfig\n",
    ") -> str:\n",
    "    \"\"\"Update the user's ticket to a new valid flight.\"\"\"\n",
    "    configuration = config.get(\"configurable\", {})\n",
    "    passenger_id = configuration.get(\"passenger_id\", None)\n",
    "    if not passenger_id:\n",
    "        raise ValueError(\"No passenger ID configured.\")\n",
    "\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\n",
    "        \"SELECT departure_airport, arrival_airport, scheduled_departure FROM flights WHERE flight_id = ?\",\n",
    "        (new_flight_id,),\n",
    "    )\n",
    "    new_flight = cursor.fetchone()\n",
    "    if not new_flight:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return \"Invalid new flight ID provided.\"\n",
    "    column_names = [column[0] for column in cursor.description]\n",
    "    new_flight_dict = dict(zip(column_names, new_flight))\n",
    "    timezone = pytz.timezone(\"Etc/GMT-3\")\n",
    "    current_time = datetime.now(tz=timezone)\n",
    "    departure_time = datetime.strptime(\n",
    "        new_flight_dict[\"scheduled_departure\"], \"%Y-%m-%d %H:%M:%S.%f%z\"\n",
    "    )\n",
    "    time_until = (departure_time - current_time).total_seconds()\n",
    "    if time_until < (3 * 3600):\n",
    "        return f\"Not permitted to reschedule to a flight that is less than 3 hours from the current time. Selected flight is at {departure_time}.\"\n",
    "\n",
    "    cursor.execute(\n",
    "        \"SELECT flight_id FROM ticket_flights WHERE ticket_no = ?\", (ticket_no,)\n",
    "    )\n",
    "    current_flight = cursor.fetchone()\n",
    "    if not current_flight:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return \"No existing ticket found for the given ticket number.\"\n",
    "\n",
    "    # Check the signed-in user actually has this ticket\n",
    "    cursor.execute(\n",
    "        \"SELECT * FROM tickets WHERE ticket_no = ? AND passenger_id = ?\",\n",
    "        (ticket_no, passenger_id),\n",
    "    )\n",
    "    current_ticket = cursor.fetchone()\n",
    "    if not current_ticket:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return f\"Current signed-in passenger with ID {passenger_id} not the owner of ticket {ticket_no}\"\n",
    "\n",
    "    # In a real application, you'd likely add additional checks here to enforce business logic,\n",
    "    # like \"does the new departure airport match the current ticket\", etc.\n",
    "    # While it's best to try to be *proactive* in 'type-hinting' policies to the LLM\n",
    "    # it's inevitably going to get things wrong, so you **also** need to ensure your\n",
    "    # API enforces valid behavior\n",
    "    cursor.execute(\n",
    "        \"UPDATE ticket_flights SET flight_id = ? WHERE ticket_no = ?\",\n",
    "        (new_flight_id, ticket_no),\n",
    "    )\n",
    "    conn.commit()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return \"Ticket successfully updated to new flight.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def cancel_ticket(ticket_no: str, *, config: RunnableConfig) -> str:\n",
    "    \"\"\"Cancel the user's ticket and remove it from the database.\"\"\"\n",
    "    configuration = config.get(\"configurable\", {})\n",
    "    passenger_id = configuration.get(\"passenger_id\", None)\n",
    "    if not passenger_id:\n",
    "        raise ValueError(\"No passenger ID configured.\")\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\n",
    "        \"SELECT flight_id FROM ticket_flights WHERE ticket_no = ?\", (ticket_no,)\n",
    "    )\n",
    "    existing_ticket = cursor.fetchone()\n",
    "    if not existing_ticket:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return \"No existing ticket found for the given ticket number.\"\n",
    "\n",
    "    # Check the signed-in user actually has this ticket\n",
    "    cursor.execute(\n",
    "        \"SELECT flight_id FROM tickets WHERE ticket_no = ? AND passenger_id = ?\",\n",
    "        (ticket_no, passenger_id),\n",
    "    )\n",
    "    current_ticket = cursor.fetchone()\n",
    "    if not current_ticket:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return f\"Current signed-in passenger with ID {passenger_id} not the owner of ticket {ticket_no}\"\n",
    "\n",
    "    cursor.execute(\"DELETE FROM ticket_flights WHERE ticket_no = ?\", (ticket_no,))\n",
    "    conn.commit()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return \"Ticket successfully cancelled.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db504cf-d26d-4494-9c1c-b1a20c43ea39",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Car Rental Tools\n",
    "\n",
    "Once a user books a flight, they likely will want to organize transportation. Define some \"car rental\" tools to let the user search for and reserve a car at their destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7af43ae-3235-4d9a-b7d9-030b8b35015f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_car_rentals(\n",
    "    location: Optional[str] = None,\n",
    "    name: Optional[str] = None,\n",
    "    price_tier: Optional[str] = None,\n",
    "    start_date: Optional[Union[datetime, date]] = None,\n",
    "    end_date: Optional[Union[datetime, date]] = None,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Search for car rentals based on location, name, price tier, start date, and end date.\n",
    "\n",
    "    Args:\n",
    "        location (Optional[str]): The location of the car rental. Defaults to None.\n",
    "        name (Optional[str]): The name of the car rental company. Defaults to None.\n",
    "        price_tier (Optional[str]): The price tier of the car rental. Defaults to None.\n",
    "        start_date (Optional[Union[datetime, date]]): The start date of the car rental. Defaults to None.\n",
    "        end_date (Optional[Union[datetime, date]]): The end date of the car rental. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of car rental dictionaries matching the search criteria.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = \"SELECT * FROM car_rentals WHERE 1=1\"\n",
    "    params = []\n",
    "\n",
    "    if location:\n",
    "        query += \" AND location LIKE ?\"\n",
    "        params.append(f\"%{location}%\")\n",
    "    if name:\n",
    "        query += \" AND name LIKE ?\"\n",
    "        params.append(f\"%{name}%\")\n",
    "    # For our tutorial, we will let you match on any dates and price tier.\n",
    "    # (since our toy dataset doesn't have much data)\n",
    "    cursor.execute(query, params)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return [\n",
    "        dict(zip([column[0] for column in cursor.description], row)) for row in results\n",
    "    ]\n",
    "\n",
    "\n",
    "@tool\n",
    "def book_car_rental(rental_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Book a car rental by its ID.\n",
    "\n",
    "    Args:\n",
    "        rental_id (int): The ID of the car rental to book.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating whether the car rental was successfully booked or not.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"UPDATE car_rentals SET booked = 1 WHERE id = ?\", (rental_id,))\n",
    "    conn.commit()\n",
    "\n",
    "    if cursor.rowcount > 0:\n",
    "        conn.close()\n",
    "        return f\"Car rental {rental_id} successfully booked.\"\n",
    "    else:\n",
    "        conn.close()\n",
    "        return f\"No car rental found with ID {rental_id}.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def update_car_rental(\n",
    "    rental_id: int,\n",
    "    start_date: Optional[Union[datetime, date]] = None,\n",
    "    end_date: Optional[Union[datetime, date]] = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Update a car rental's start and end dates by its ID.\n",
    "\n",
    "    Args:\n",
    "        rental_id (int): The ID of the car rental to update.\n",
    "        start_date (Optional[Union[datetime, date]]): The new start date of the car rental. Defaults to None.\n",
    "        end_date (Optional[Union[datetime, date]]): The new end date of the car rental. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating whether the car rental was successfully updated or not.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    if start_date:\n",
    "        cursor.execute(\n",
    "            \"UPDATE car_rentals SET start_date = ? WHERE id = ?\",\n",
    "            (start_date, rental_id),\n",
    "        )\n",
    "    if end_date:\n",
    "        cursor.execute(\n",
    "            \"UPDATE car_rentals SET end_date = ? WHERE id = ?\", (end_date, rental_id)\n",
    "        )\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    if cursor.rowcount > 0:\n",
    "        conn.close()\n",
    "        return f\"Car rental {rental_id} successfully updated.\"\n",
    "    else:\n",
    "        conn.close()\n",
    "        return f\"No car rental found with ID {rental_id}.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def cancel_car_rental(rental_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Cancel a car rental by its ID.\n",
    "\n",
    "    Args:\n",
    "        rental_id (int): The ID of the car rental to cancel.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating whether the car rental was successfully cancelled or not.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"UPDATE car_rentals SET booked = 0 WHERE id = ?\", (rental_id,))\n",
    "    conn.commit()\n",
    "\n",
    "    if cursor.rowcount > 0:\n",
    "        conn.close()\n",
    "        return f\"Car rental {rental_id} successfully cancelled.\"\n",
    "    else:\n",
    "        conn.close()\n",
    "        return f\"No car rental found with ID {rental_id}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290e0ad3-307a-4976-aa00-210dce1157ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Hotels\n",
    "\n",
    "The user has to sleep! Define some tools to search for and manage hotel reservations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51fc72b5-c3a6-42b8-84c6-024be503fc45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_hotels(\n",
    "    location: Optional[str] = None,\n",
    "    name: Optional[str] = None,\n",
    "    price_tier: Optional[str] = None,\n",
    "    checkin_date: Optional[Union[datetime, date]] = None,\n",
    "    checkout_date: Optional[Union[datetime, date]] = None,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Search for hotels based on location, name, price tier, check-in date, and check-out date.\n",
    "\n",
    "    Args:\n",
    "        location (Optional[str]): The location of the hotel. Defaults to None.\n",
    "        name (Optional[str]): The name of the hotel. Defaults to None.\n",
    "        price_tier (Optional[str]): The price tier of the hotel. Defaults to None. Examples: Midscale, Upper Midscale, Upscale, Luxury\n",
    "        checkin_date (Optional[Union[datetime, date]]): The check-in date of the hotel. Defaults to None.\n",
    "        checkout_date (Optional[Union[datetime, date]]): The check-out date of the hotel. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of hotel dictionaries matching the search criteria.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = \"SELECT * FROM hotels WHERE 1=1\"\n",
    "    params = []\n",
    "\n",
    "    if location:\n",
    "        query += \" AND location LIKE ?\"\n",
    "        params.append(f\"%{location}%\")\n",
    "    if name:\n",
    "        query += \" AND name LIKE ?\"\n",
    "        params.append(f\"%{name}%\")\n",
    "    # For the sake of this tutorial, we will let you match on any dates and price tier.\n",
    "    cursor.execute(query, params)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return [\n",
    "        dict(zip([column[0] for column in cursor.description], row)) for row in results\n",
    "    ]\n",
    "\n",
    "\n",
    "@tool\n",
    "def book_hotel(hotel_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Book a hotel by its ID.\n",
    "\n",
    "    Args:\n",
    "        hotel_id (int): The ID of the hotel to book.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating whether the hotel was successfully booked or not.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"UPDATE hotels SET booked = 1 WHERE id = ?\", (hotel_id,))\n",
    "    conn.commit()\n",
    "\n",
    "    if cursor.rowcount > 0:\n",
    "        conn.close()\n",
    "        return f\"Hotel {hotel_id} successfully booked.\"\n",
    "    else:\n",
    "        conn.close()\n",
    "        return f\"No hotel found with ID {hotel_id}.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def update_hotel(\n",
    "    hotel_id: int,\n",
    "    checkin_date: Optional[Union[datetime, date]] = None,\n",
    "    checkout_date: Optional[Union[datetime, date]] = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Update a hotel's check-in and check-out dates by its ID.\n",
    "\n",
    "    Args:\n",
    "        hotel_id (int): The ID of the hotel to update.\n",
    "        checkin_date (Optional[Union[datetime, date]]): The new check-in date of the hotel. Defaults to None.\n",
    "        checkout_date (Optional[Union[datetime, date]]): The new check-out date of the hotel. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating whether the hotel was successfully updated or not.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    if checkin_date:\n",
    "        cursor.execute(\n",
    "            \"UPDATE hotels SET checkin_date = ? WHERE id = ?\", (checkin_date, hotel_id)\n",
    "        )\n",
    "    if checkout_date:\n",
    "        cursor.execute(\n",
    "            \"UPDATE hotels SET checkout_date = ? WHERE id = ?\",\n",
    "            (checkout_date, hotel_id),\n",
    "        )\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    if cursor.rowcount > 0:\n",
    "        conn.close()\n",
    "        return f\"Hotel {hotel_id} successfully updated.\"\n",
    "    else:\n",
    "        conn.close()\n",
    "        return f\"No hotel found with ID {hotel_id}.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def cancel_hotel(hotel_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Cancel a hotel by its ID.\n",
    "\n",
    "    Args:\n",
    "        hotel_id (int): The ID of the hotel to cancel.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating whether the hotel was successfully cancelled or not.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"UPDATE hotels SET booked = 0 WHERE id = ?\", (hotel_id,))\n",
    "    conn.commit()\n",
    "\n",
    "    if cursor.rowcount > 0:\n",
    "        conn.close()\n",
    "        return f\"Hotel {hotel_id} successfully cancelled.\"\n",
    "    else:\n",
    "        conn.close()\n",
    "        return f\"No hotel found with ID {hotel_id}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c42f669-e892-48b8-8f3c-2ba6bdac9c97",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Excursions\n",
    "\n",
    "Finally, define some tools to let the user search for things to do (and make reservations) once they arrive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "234c1071-03ec-4d56-832a-8179e63017c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_trip_recommendations(\n",
    "    location: Optional[str] = None,\n",
    "    name: Optional[str] = None,\n",
    "    keywords: Optional[str] = None,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Search for trip recommendations based on location, name, and keywords.\n",
    "\n",
    "    Args:\n",
    "        location (Optional[str]): The location of the trip recommendation. Defaults to None.\n",
    "        name (Optional[str]): The name of the trip recommendation. Defaults to None.\n",
    "        keywords (Optional[str]): The keywords associated with the trip recommendation. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of trip recommendation dictionaries matching the search criteria.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = \"SELECT * FROM trip_recommendations WHERE 1=1\"\n",
    "    params = []\n",
    "\n",
    "    if location:\n",
    "        query += \" AND location LIKE ?\"\n",
    "        params.append(f\"%{location}%\")\n",
    "    if name:\n",
    "        query += \" AND name LIKE ?\"\n",
    "        params.append(f\"%{name}%\")\n",
    "    if keywords:\n",
    "        keyword_list = keywords.split(\",\")\n",
    "        keyword_conditions = \" OR \".join([\"keywords LIKE ?\" for _ in keyword_list])\n",
    "        query += f\" AND ({keyword_conditions})\"\n",
    "        params.extend([f\"%{keyword.strip()}%\" for keyword in keyword_list])\n",
    "\n",
    "    cursor.execute(query, params)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return [\n",
    "        dict(zip([column[0] for column in cursor.description], row)) for row in results\n",
    "    ]\n",
    "\n",
    "\n",
    "@tool\n",
    "def book_excursion(recommendation_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Book a excursion by its recommendation ID.\n",
    "\n",
    "    Args:\n",
    "        recommendation_id (int): The ID of the trip recommendation to book.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating whether the trip recommendation was successfully booked or not.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\n",
    "        \"UPDATE trip_recommendations SET booked = 1 WHERE id = ?\", (recommendation_id,)\n",
    "    )\n",
    "    conn.commit()\n",
    "\n",
    "    if cursor.rowcount > 0:\n",
    "        conn.close()\n",
    "        return f\"Trip recommendation {recommendation_id} successfully booked.\"\n",
    "    else:\n",
    "        conn.close()\n",
    "        return f\"No trip recommendation found with ID {recommendation_id}.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def update_excursion(recommendation_id: int, details: str) -> str:\n",
    "    \"\"\"\n",
    "    Update a trip recommendation's details by its ID.\n",
    "\n",
    "    Args:\n",
    "        recommendation_id (int): The ID of the trip recommendation to update.\n",
    "        details (str): The new details of the trip recommendation.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating whether the trip recommendation was successfully updated or not.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\n",
    "        \"UPDATE trip_recommendations SET details = ? WHERE id = ?\",\n",
    "        (details, recommendation_id),\n",
    "    )\n",
    "    conn.commit()\n",
    "\n",
    "    if cursor.rowcount > 0:\n",
    "        conn.close()\n",
    "        return f\"Trip recommendation {recommendation_id} successfully updated.\"\n",
    "    else:\n",
    "        conn.close()\n",
    "        return f\"No trip recommendation found with ID {recommendation_id}.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def cancel_excursion(recommendation_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Cancel a trip recommendation by its ID.\n",
    "\n",
    "    Args:\n",
    "        recommendation_id (int): The ID of the trip recommendation to cancel.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating whether the trip recommendation was successfully cancelled or not.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\n",
    "        \"UPDATE trip_recommendations SET booked = 0 WHERE id = ?\", (recommendation_id,)\n",
    "    )\n",
    "    conn.commit()\n",
    "\n",
    "    if cursor.rowcount > 0:\n",
    "        conn.close()\n",
    "        return f\"Trip recommendation {recommendation_id} successfully cancelled.\"\n",
    "    else:\n",
    "        conn.close()\n",
    "        return f\"No trip recommendation found with ID {recommendation_id}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f57ca8-9ea8-4e16-a5fd-31d32fe08e1d",
   "metadata": {},
   "source": [
    "#### Utilities\n",
    "\n",
    "Define helper functions to pretty print the messages in the graph while we debug it and to give our tool node error handling (by adding the error to the chat history)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "854fa2e7-1b85-4f70-a4ae-d0b2ffdbd784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce361684-76ea-4d7b-a17a-6f9e0f50a13c",
   "metadata": {},
   "source": [
    "# Agent\n",
    "In this section, we will define a simple Zero-shot agent as the assistant, give the agent **all** of our tools, and prompt it to use them judiciously to assist the user.\n",
    "#### State\n",
    "\n",
    "Define our `StateGraph`'s state as a typed dictionary containing an append-only list of messages. These messages form the chat history, which is all the state our simple assistant needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c200f20f-9393-46e6-b411-81895434cc81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5d24c8-7892-4af8-8c10-0d8356d4ab45",
   "metadata": {},
   "source": [
    "#### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f404bea8-fe9c-4c8a-8863-f13af03a4530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup boto3 config to allow for retrying\n",
    "region_name = \"us-east-1\"\n",
    "my_config = Config(\n",
    "    region_name = region_name,\n",
    "    signature_version = 'v4',\n",
    "    retries = {\n",
    "        'max_attempts': 3,\n",
    "        'mode': 'standard'\n",
    "    }\n",
    ")\n",
    "\n",
    "# setup bedrock runtime client \n",
    "sagemaker_runtime = boto3.client(\n",
    "    service_name = \"sagemaker-runtime\",\n",
    "    region_name = region_name,\n",
    ")\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name = \"bedrock-runtime\",\n",
    "    config = my_config,\n",
    ")\n",
    "\n",
    "# \"anthropic.claude-v2:1\"\n",
    "# \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "# \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "bedrock_model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "model_kwargs =  { \n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"Human\"],\n",
    "}\n",
    "bedrock_llm = ChatBedrock(\n",
    "    client = bedrock_runtime,\n",
    "    model_id = bedrock_model_id,\n",
    "    model_kwargs = model_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb27fead-531e-497f-a480-8057e97e472e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            configuration = config.get(\"configurable\", {})\n",
    "            passenger_id = configuration.get(\"passenger_id\", None)\n",
    "            state = {**state, \"user_info\": passenger_id}\n",
    "            result = self.runnable.invoke(state)\n",
    "            # If the LLM happens to return an empty response, we will re-prompt it\n",
    "            # for an actual response.\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful customer support assistant for Swiss Airlines. \"\n",
    "            \" Use the provided tools to search for flights, company policies, and other information to assist the user's queries. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\n\\nCurrent user:\\n<User>\\n{user_info}\\n</User>\"\n",
    "            \"\\nCurrent time: {time}.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now())\n",
    "\n",
    "part_1_tools = [\n",
    "    fetch_user_flight_information,\n",
    "    search_flights,\n",
    "    update_ticket_to_new_flight,\n",
    "    cancel_ticket,\n",
    "    search_car_rentals,\n",
    "    book_car_rental,\n",
    "    update_car_rental,\n",
    "    cancel_car_rental,\n",
    "    search_hotels,\n",
    "    book_hotel,\n",
    "    update_hotel,\n",
    "    cancel_hotel,\n",
    "    search_trip_recommendations,\n",
    "    book_excursion,\n",
    "    update_excursion,\n",
    "    cancel_excursion,\n",
    "]\n",
    "part_1_assistant_runnable = primary_assistant_prompt | bedrock_llm.bind_tools(part_1_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b621d5-3873-40cb-84cc-28bc17a37f0f",
   "metadata": {},
   "source": [
    "#### Define Graph\n",
    "\n",
    "Now, create the graph. The graph is the final assistant for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cab9e45-1764-4f97-8248-d8041111014c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", Assistant(part_1_assistant_runnable))\n",
    "builder.add_node(\"tools\", create_tool_node_with_fallback(part_1_tools))\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# The checkpointer lets the graph persist its state\n",
    "# this is a complete memory for the entire graph.\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67a905-cb38-4ded-8ba0-42aa58e12bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c57c53d-7808-46a9-baba-636b996e1096",
   "metadata": {},
   "source": [
    "# Questions & Agent responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e58fb42-7b01-4cfd-95a5-5bc87bee6603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions_path = \"data/travel_data_gt.csv\"\n",
    "questions_data = pd.read_csv(questions_path)\n",
    "\n",
    "# Update with the backup file so we can restart from the original place in each section\n",
    "db = update_dates(db)\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # The passenger_id is used in our flight tools to\n",
    "        # fetch the user's flight information\n",
    "        \"passenger_id\": \"3442 587242\",\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "012c4307-bb8d-44cb-8004-316c8634ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import *\n",
    "output_path =\"data/travel_data_tst.csv\"\n",
    "agent_params = {\"agent\": graph,\n",
    "               \"agent_node_name\": \"assistant\",\n",
    "                \"tool_node_name\": \"tools\"\n",
    "               }\n",
    "save_agent_responses(\"langgraph\", agent_params, config, \n",
    "                         output_path, questions_data, question_col=\"Questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689fd47-7fca-4906-878e-455464cd9758",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2453e3c4-ac7f-4af0-8fd7-9f925e5fbe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"travel_data_tst.csv\"\n",
    "df = pd.read_csv(f\"data/{filename}\")\n",
    "\n",
    "df[\"called_tools\"] = df[\"called_tools\"].apply(lambda x: literal_eval(x) if \"[\" in x else x)\n",
    "df[\"called_tools_args\"] = df[\"called_tools_args\"].apply(lambda x: literal_eval(x))\n",
    "df[\"responses\"] = df[\"responses\"].apply(lambda x: literal_eval(x))\n",
    "df[\"Tools\"] = df[\"Tools\"].apply(lambda x:  literal_eval(x))\n",
    "df[\"Arguments\"] = df[\"Arguments\"].apply(lambda x:  literal_eval(x))\n",
    "\n",
    "df['ground_truths']=df['Expected Output'].apply(lambda x: [x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5120e842-e622-48ca-8415-2be18393d48b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### available_tools fetch_user_flight_information, search_flights, update_ticket_to_new_flight, cancel_ticket, search_car_rentals, book_car_rental, update_car_rental, cancel_car_rental, search_hotels, book_hotel, update_hotel, cancel_hotel, search_trip_recommendations, book_excursion, update_excursion, cancel_excursion\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd26e5f9211445e86351bb6ffc2a8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py\", line 1015, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n"
     ]
    }
   ],
   "source": [
    "metric_list = [\"incorrect_tool_pct\",\n",
    "               \"missed_tool_pct\",\n",
    "               \"tools_args_acc\",\n",
    "               \"tool_calling_perf\",\n",
    "               \"response_acc_llm_judge\",\n",
    "               \"answer_precision\",\n",
    "               \"answer_recall\",\n",
    "               \"answer_correctness\",\n",
    "               \"answer_similarity\",\n",
    "               \"answer_relevancy\",\n",
    "               \"tool_calling_accuracy\"\n",
    "              ]\n",
    "available_tools = \"fetch_user_flight_information, search_flights, update_ticket_to_new_flight, cancel_ticket, search_car_rentals, book_car_rental, update_car_rental, cancel_car_rental, search_hotels, book_hotel, update_hotel, cancel_hotel, search_trip_recommendations, book_excursion, update_excursion, cancel_excursion\"\n",
    "res = calc_metrics(df, metric_list, available_tools=available_tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26096e97-202d-4863-a0d1-6d1f841d2cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>incorrect_tool_pct</th>\n",
       "      <th>missed_tool_pct</th>\n",
       "      <th>tools_args_acc</th>\n",
       "      <th>tool_calling_perf</th>\n",
       "      <th>response_acc_llm_judge</th>\n",
       "      <th>answer_precision</th>\n",
       "      <th>answer_recall</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>answer_similarity</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>tool_calling_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi there, what time is my flight?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.828627</td>\n",
       "      <td>0.914509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Update my flight and book it for first flight ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.419332</td>\n",
       "      <td>0.677329</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I like a cheap hotel for my 7 days stay. Provi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.412452</td>\n",
       "      <td>0.649807</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Book the cheapest hotel.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307170</td>\n",
       "      <td>0.628679</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cool so now what recommendations do you have f...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.540465</td>\n",
       "      <td>0.777246</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OK great pick one and book it for my second da...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.796187</td>\n",
       "      <td>0.784746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  incorrect_tool_pct  \\\n",
       "0                  Hi there, what time is my flight?                 0.0   \n",
       "1  Update my flight and book it for first flight ...                 0.0   \n",
       "2  I like a cheap hotel for my 7 days stay. Provi...                 0.0   \n",
       "3                           Book the cheapest hotel.                 0.0   \n",
       "4  Cool so now what recommendations do you have f...                 0.0   \n",
       "5  OK great pick one and book it for my second da...                 0.0   \n",
       "\n",
       "   missed_tool_pct  tools_args_acc  tool_calling_perf  response_acc_llm_judge  \\\n",
       "0              0.0        1.000000           1.000000                     0.9   \n",
       "1              0.0        0.666667           0.888889                     0.7   \n",
       "2              0.5        0.125000           0.541667                     0.8   \n",
       "3              0.0        0.000000           0.666667                     0.8   \n",
       "4              0.0        1.000000           1.000000                     0.9   \n",
       "5              0.0        1.000000           1.000000                     0.8   \n",
       "\n",
       "   answer_precision  answer_recall  answer_correctness  answer_similarity  \\\n",
       "0          0.666667       0.666667            0.828627           0.914509   \n",
       "1          0.250000       0.222222            0.419332           0.677329   \n",
       "2          0.428571       0.285714            0.412452           0.649807   \n",
       "3          0.000000       0.000000            0.307170           0.628679   \n",
       "4          0.800000       0.818182            0.540465           0.777246   \n",
       "5          0.333333       0.428571            0.796187           0.784746   \n",
       "\n",
       "   answer_relevancy  tool_calling_accuracy  \n",
       "0               1.0                    1.0  \n",
       "1               0.9                    0.8  \n",
       "2               0.9                    0.8  \n",
       "3               0.9                    0.9  \n",
       "4               0.9                    1.0  \n",
       "5               1.0                    0.8  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[[\"Questions\"]+metric_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf15ef-341c-458a-bb28-566fd65e1b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
